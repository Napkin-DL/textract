{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Textract\n",
    "Amazon Textract makes it easy to add document text detection and analysis to your applications. The Amazon Textract Text Detection API can detect text in a variety of documents including financial reports, medical records, and tax forms. For documents with structured data, you can use the Amazon Textract Document Analysis API to extract text, forms and tables.\n",
    "Amazon Textract provides synchronous operations for processing small, single-page, documents and for getting near real-time responses. Amazon Textract also provides asynchronous operations that you can use to process larger, multipage documents. Asynchronous responses aren't in real time.\n",
    "\n",
    "\n",
    "## 1. synchronous operations\n",
    "\n",
    "Synchronous operations can process **JPEG** and **PNG** format images. Typically these are images of single-page documents that you've scanned.\n",
    "\n",
    "For Amazon Textract synchronous operations, you can use input documents that are stored in an **Amazon S3 bucket**, or you can pass **base64-encoded image bytes**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detects text in a document stored in an S3 bucket. Display polygon box around text and angled text \n",
    "import boto3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import textract.util as tu\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textract = boto3.client('textract')\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket=''        ## S3 데이터 버킷 정보, 실제 분석한 파일(jpg, png, pdf)를 올리는 장소\n",
    "document = ''    ## 파일 명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Detecting Text\n",
    "\n",
    "return only the text detected in a document\n",
    "> Sync method:  **detect_document_text()**   \n",
    "> Async method: **start_document_text_detection()**\n",
    "\n",
    "\n",
    "- The lines and words of detected text\n",
    "- The relationships between the lines and words of detected text\n",
    "- The page that the detected text appears on\n",
    "- The location of the lines and words of text on the document page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#process using S3 object\n",
    "response = textract.detect_document_text(\n",
    "    Document={'S3Object': {'Bucket': bucket, 'Name': document}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1) Post-processing for Detecting Text\n",
    " - the location and geometry of items found on a documented page, such as lines and words\n",
    " - Bounding box: height, left (X coordinate), top (Y coordinate), and width as a ratio of the overall document page height, left, top, and width, repectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image, image, blocks = tu.get_sync_detect_document_text(bucket, document, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2) Display an original document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_x, fig_y = 20, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (fig_x,fig_y))\n",
    "plt.imshow(np.array(ori_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3) Display items location on a document page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (fig_x,fig_y))\n",
    "plt.imshow(np.array(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Analyzing Text\n",
    "\n",
    "Amazon Textract analyzes documents and forms for relationships between detected text. Amazon Textract analysis operations return 3 categories of text extraction — text, forms, and tables.\n",
    "\n",
    "> Sync method:  **analyze_document()**   \n",
    "> Async method: **start_document_analysis()**\n",
    "\n",
    "\n",
    "- The lines and words of detected text\n",
    "- The relationships between detected items\n",
    "- The page that the item was detected on\n",
    "- The location of the item on the document page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1) Change Image to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image, image, stream = tu.s3_to_image(bucket, document)\n",
    "image_binary = stream.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2) Perform analyzing document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = textract.analyze_document(Document={'Bytes': image_binary},\n",
    "    FeatureTypes=[\"TABLES\", \"FORMS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3) Post-processing for Analyzing Document\n",
    "the location and geometry of key-value pairs, tables, cells, and selection elements.\n",
    " - Bounding box: height, left (X coordinate), top (Y coordinate), and width as a ratio of the overall document page height, left, top, and width, repectively\n",
    " - Polygon: points in the polygon array to display a finer-grain bounding box around a Block object. \n",
    "\n",
    "Multiply the X coordinate by the document page width, and multiply the Y coordinate by the document page height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, blocks = tu.get_sync_analyze_document(image, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4) The results of analyzing Text in a document page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = tu.get_page(blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Detecting Entitiy for Amazon Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tu.detect_entities_for_comprehend(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extracting Key-Value Pairs from a Form Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_map, value_map, block_map = tu.get_kv_map(blocks)\n",
    "\n",
    "# Get Key Value relationship\n",
    "kvs = tu.get_kv_relationship(key_map, value_map, block_map)\n",
    "print(\"\\n\\n== FOUND KEY : VALUE pairs ===\\n\")\n",
    "tu.print_kvs(kvs)\n",
    "\n",
    "# Start searching a key value\n",
    "while input('\\n Do you want to search a value for a key? (enter \"n\" for exit) ') != 'n':\n",
    "    search_key = input('\\n Enter a search key:')\n",
    "    print('The value is:', tu.search_value(kvs, search_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limits\n",
    "\n",
    " - 최대 문서 이미지 (JPEG / PNG) 크기는 10MB입니다.\n",
    " - 최대 PDF 파일 크기는 500MB입니다.\n",
    " - PDF 파일의 최대 페이지 수는 3000입니다.\n",
    " - PDF의 미디어 크기의 최대 높이/너비는 40 인치 또는 2880 포인트입니다.\n",
    " - 텍스트의 최소 높이는 15 픽셀이며, 150 DPI에서는 이 값은 8 pt 글꼴과 같습니다.\n",
    " - 세로 축에서 최대 +/- 10 % 회전된 문서는 가능하며, 텍스트는 문서 내에서 가로로 정렬된 텍스트가 가능합니다.\n",
    " - Amazon Textract는 영어 텍스트 감지 만 지원합니다.\n",
    " - Amazon Textract는 필기 감지를 지원하지 않습니다. \n",
    " - Amazon Textract 동기 작업 (DetectDocumentText 및 AnalyzeDocument)은 PNG 및 JPEG 이미지 형식을 지원합니다. \n",
    " - 비동기 작업 (StartDocumentTextDetection, StartDocumentAnalysis)도 PDF 파일 형식을 지원합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "> [Other Example](https://docs.aws.amazon.com/textract/latest/dg/other-examples.html)  \n",
    "> [Index your pile of papers with Amazon Textract, Amazon Comprehend and Amazon Elasticsearch Service](https://github.com/aws-samples/workshop-textract-comprehend-es)  \n",
    "> [amazon-textract-enhancer](https://github.com/aws-samples/amazon-textract-enhancer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}