{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Textract\n",
    "Amazon Textract makes it easy to add document text detection and analysis to your applications. The Amazon Textract Text Detection API can detect text in a variety of documents including financial reports, medical records, and tax forms. For documents with structured data, you can use the Amazon Textract Document Analysis API to extract text, forms and tables.\n",
    "Amazon Textract provides synchronous operations for processing small, single-page, documents and for getting near real-time responses. Amazon Textract also provides asynchronous operations that you can use to process larger, multipage documents. Asynchronous responses aren't in real time.\n",
    "\n",
    "\n",
    "## 1. synchronous operations\n",
    "\n",
    "Synchronous operations can process **JPEG** and **PNG** format images. Typically these are images of single-page documents that you've scanned.\n",
    "\n",
    "For Amazon Textract synchronous operations, you can use input documents that are stored in an **Amazon S3 bucket**, or you can pass **base64-encoded image bytes**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detects text in a document stored in an S3 bucket. Display polygon box around text and angled text \n",
    "import boto3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import textract.util as tu\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textract = boto3.client('textract')\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">아래 Setting을 완성해 주시기 바랍니다!!!</span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## S3 데이터 버킷 정보, 실제 분석한 파일(jpg, png)를 올리는 장소로 CloudFormation에 생성된 bucket을 넣어주시면 됩니다.\n",
    "bucket= 'amazon-textract-demo-0208' \n",
    "\n",
    "## 분석할 문서 이름을 넣어주시기 바랍니다.\n",
    "document = '1853_Subscription_document.jpeg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Detecting Text\n",
    "\n",
    "return only the text detected in a document\n",
    "> Sync method:  **detect_document_text()**   \n",
    "> Async method: **start_document_text_detection()**\n",
    "\n",
    "\n",
    "- The lines and words of detected text\n",
    "- The relationships between the lines and words of detected text\n",
    "- The page that the detected text appears on\n",
    "- The location of the lines and words of text on the document page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#process using S3 object\n",
    "response = textract.detect_document_text(\n",
    "    Document={'S3Object': {'Bucket': bucket, 'Name': document}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1) Post-processing for Detecting Text\n",
    " - the location and geometry of items found on a documented page, such as lines and words\n",
    " - Bounding box: height, left (X coordinate), top (Y coordinate), and width as a ratio of the overall document page height, left, top, and width, repectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image, image, blocks = tu.get_sync_detect_document_text(bucket, document, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2) Display an original document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_x, fig_y = 20, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Image\")\n",
    "plt.figure(figsize = (fig_x,fig_y))\n",
    "plt.imshow(np.array(ori_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3) Display items location on a document page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Detecting Textract\")\n",
    "plt.figure(figsize = (fig_x,fig_y))\n",
    "plt.imshow(np.array(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Analyzing Text\n",
    "\n",
    "Amazon Textract analyzes documents and forms for relationships between detected text. Amazon Textract analysis operations return 3 categories of text extraction — text, forms, and tables.\n",
    "\n",
    "> Sync method:  **analyze_document()**   \n",
    "> Async method: **start_document_analysis()**\n",
    "\n",
    "\n",
    "- The lines and words of detected text\n",
    "- The relationships between detected items\n",
    "- The page that the item was detected on\n",
    "- The location of the item on the document page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1) Change Image to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_image, image, stream = tu.s3_to_image(bucket, document)\n",
    "image_binary = stream.getvalue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2) Perform analyzing document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = textract.analyze_document(Document={'Bytes': image_binary},\n",
    "    FeatureTypes=[\"TABLES\", \"FORMS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3) Post-processing for Analyzing Document\n",
    "the location and geometry of key-value pairs, tables, cells, and selection elements.\n",
    " - Bounding box: height, left (X coordinate), top (Y coordinate), and width as a ratio of the overall document page height, left, top, and width, repectively\n",
    " - Polygon: points in the polygon array to display a finer-grain bounding box around a Block object. \n",
    "\n",
    "Multiply the X coordinate by the document page width, and multiply the Y coordinate by the document page height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ori_image, image, blocks = tu.get_sync_analyze_document(bucket, document, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-4) The results of analyzing Text in a document page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = tu.get_page(blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Detecting Entitiy for Amazon Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = tu.detect_entities_for_comprehend(page[:1000])\n",
    "except Exception as e:\n",
    "    print(\"Exception : {}\".format(e))\n",
    "    print(\"In case that Exception is TextSizeLimitExceededException, Max length of request text allowed is 5000 bytes. So you can use 2 and 3 notebooks instead of this notebook.\")\n",
    "    pass\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extracting Key-Value Pairs from a Form Document Using Amazon Comprehend\n",
    "\n",
    "The results of the Amazon Comprehend don't not extract all key and values from Textract ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_map, value_map, block_map = tu.get_kv_map(blocks)\n",
    "\n",
    "# Get Key Value relationship\n",
    "kvs = tu.get_kv_relationship(key_map, value_map, block_map)\n",
    "print(\"\\n\\n== FOUND KEY : VALUE pairs ===\\n\")\n",
    "tu.print_kvs(kvs)\n",
    "\n",
    "# Start searching a key value\n",
    "while input('\\n Do you want to search a value for a key? (enter \"n\" for exit) ') != 'n':\n",
    "    search_key = input('\\n Enter a search key:')\n",
    "    print('The value is:', tu.search_value(kvs, search_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limits\n",
    "\n",
    " - 최대 문서 이미지 (JPEG / PNG) 크기는 10MB입니다.\n",
    " - 최대 PDF 파일 크기는 500MB입니다.\n",
    " - PDF 파일의 최대 페이지 수는 3000입니다.\n",
    " - PDF의 미디어 크기의 최대 높이/너비는 40 인치 또는 2880 포인트입니다.\n",
    " - 텍스트의 최소 높이는 15 픽셀이며, 150 DPI에서는 이 값은 8 pt 글꼴과 같습니다.\n",
    " - Amazon Textract는 평면 내 45도 회전과 같은 모든 평면 내 문서 회전을 지원합니다.\n",
    " - Text는 문서 내에서 수평으로 정렬이 가능하지만, 수직으로는 text 정렬을 지원하지 않습니다.\n",
    " - Amazon Textract는 영어, 스페인어, 독일어, 프랑스어, 이탈리아어, 포르투갈어의 텍스트 감지를 지원합니다. 결과에는 탐지된 언어가 무엇인지 반환하지는 않습니다.\n",
    " - Amazon Textract는 영어 필기 감지와 프린트된 문자 인식을 지원합니다. \n",
    " - Amazon Textract는 0에서 9까지의 숫자, 영문 알파벳, 다음 특수 문자를 지원합니다: !\"#$%''&()*+,-./:;=?@[\\]^_`{|}~ °€£¥₹><\n",
    "\n",
    "\n",
    " - Amazon Textract 동기 작업 (DetectDocumentText 및 AnalyzeDocument)은 PNG 및 JPEG 이미지 형식을 지원합니다. \n",
    " - 비동기 작업 (StartDocumentTextDetection, StartDocumentAnalysis)은 PNG, JPEG, PDF 파일 형식을 지원합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "> [Other Example](https://docs.aws.amazon.com/textract/latest/dg/other-examples.html)  \n",
    "> [Index your pile of papers with Amazon Textract, Amazon Comprehend and Amazon Elasticsearch Service](https://github.com/aws-samples/workshop-textract-comprehend-es)  \n",
    "> [amazon-textract-enhancer](https://github.com/aws-samples/amazon-textract-enhancer)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
